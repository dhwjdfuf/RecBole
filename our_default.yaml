# Atomic File Format
field_separator: "\t"           # (str) Separator of different columns in atomic files.
seq_separator: " "              # (str) Separator inside the sequence features.

# Basic Information
USER_ID_FIELD: user_id          # (str) Field name of user ID feature.
ITEM_ID_FIELD: item_id          # (str) Field name of item ID feature.
RATING_FIELD: ~                 # (str) Field name of rating feature.
TIME_FIELD: timestamp           # (str) Field name of timestamp feature.
load_col:                       # (dict) The suffix of atomic files: (list) field names to be loaded.
    inter: [user_id, item_id, timestamp]
ITEM_LIST_LENGTH_FIELD: item_length    # (str) Field name of the feature representing item sequences' length. 
LIST_SUFFIX: _list                     # (str) Suffix of field names which are generated as sequences.
MAX_ITEM_LIST_LENGTH: 250              # (int) Maximum length of each generated sequence.


# Evaluation Settings
eval_args:                         # (dict) 4 keys: group_by, order, split, and mode
  split: {'LS':'valid_and_test'}   # (dict) The splitting strategy ranging in ['RS','LS'].
  group_by: user                   # (str) The grouping strategy ranging in ['user', 'none'].
  order: TO                        # (str) The ordering strategy ranging in ['RO', 'TO'].
  mode: full                       # (str) The evaluation mode ranging in ['full','unixxx','popxxx','labeled'].
metrics: ["NDCG","Hit"]            # (list or str) Evaluation metrics.
topk: [5, 10, 50, 100]                      # (list or int or None) The value of k for topk evaluation metrics.
valid_metric: Hit@10               # (str) The evaluation metric for early stopping. 
valid_metric_bigger: True          # (bool) Whether to take a bigger valid metric value as a better result.
eval_batch_size: 1024              # (int) The evaluation batch size.
metric_decimal_place: 4            # (int) The decimal place of metric scores.


# Training Settings, overall.yaml
epochs: 300                     # (int) The number of training epochs.
train_batch_size: 1024          # (int) The training batch size.
train_neg_sample_args: ~        # (dict) Negative sampling configuration for model training.
eval_step: 1                    # (int) The number of training epochs before an evaluation on the valid dataset.
stopping_step: 10               # (int) The threshold for validation-based early stopping.
clip_grad_norm: ~               # (dict) The args of clip_grad_norm_ which will clip gradient norm of model. 



# Environment Settings
gpu_id: '2'                     # (str) The id of GPU device(s).
use_gpu: True                   # (bool) Whether or not to use GPU.

seed: 42                        # (int) Random seed.
state: INFO                     # (str) Logging level.
reproducibility: True           # (bool) Whether or not to make results reproducible.
checkpoint_dir: 'saved'         # (str) The path to save checkpoint file.
show_progress: True             # (bool) Whether or not to show the progress bar of every epoch. 
save_dataset: True             # (bool) Whether or not to save filtered dataset.
dataset_save_path: ~          # (str) The path of saved dataset.
save_dataloaders: True         # (bool) Whether or not save split dataloaders.
dataloaders_save_path: ~        # (str) The path of saved dataloaders.
log_wandb: False                # (bool) Whether or not to use Weights & Biases(W&B).
wandb_project: 'recbole'        # (str) The project to conduct experiments in W&B.
shuffle: True                   # (bool) Whether or not to shuffle the training data before each epoch.


train_neg_sample_args: ~        # (dict) Negative sampling configuration for model training. 

